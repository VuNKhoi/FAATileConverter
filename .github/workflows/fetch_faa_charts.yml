name: FAA Charts Download, Convert & Upload

on:
  # TODO: Re-enable schedule triggers when testing is complete
  # schedule:
  #   - cron: '0 6 * * 3'  # Every Wednesday at 06:00 UTC
  #   - cron: '0 6 * * 4'  # Every Thursday at 06:00 UTC
  #   - cron: '0 6 * * 5'  # Every Friday at 06:00 UTC
  workflow_dispatch:  # Manual trigger option

permissions:
  contents: read
  actions: read

jobs:
  download_convert_upload:
    strategy:
      matrix:
        chart_type: [sectional, ifr_low, ifr_high]
    runs-on: ubuntu-latest
    env:
      AWS_DEFAULT_REGION: us-east-1
      S3_BUCKET: faa-converted-charts
      CHART_TYPE: ${{ matrix.chart_type }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y gdal-bin python3-gdal unzip

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_DEFAULT_REGION }}

      - name: Install Python packages
        run: pip install --no-cache-dir -r requirements.txt

      - name: Check if chart is current (marker file check)
        id: check_current
        run: |
          chart_type=${{ matrix.chart_type }}
          marker_file="downloads/$chart_type/.current_marker"
          # Simulate marker check: replace with your actual logic or script
          if [ -f "$marker_file" ]; then
            echo "Marker file exists for $chart_type. Checking if current..."
            # Replace this with your actual staleness check logic
            if grep -q 'current' "$marker_file"; then
              echo "Chart $chart_type is current. Skipping download, convert, and upload."
              echo "current=true" >> $GITHUB_OUTPUT
              exit 0
            else
              echo "Chart $chart_type is obsolete. Proceeding."
              echo "current=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "No marker file for $chart_type. Proceeding."
            echo "current=false" >> $GITHUB_OUTPUT
          fi

      - name: Run download and unzip script
        if: steps.check_current.outputs.current != 'true'
        run: python scripts/download_faa_charts.py --chart-type ${{ matrix.chart_type }} --check-current

      - name: Convert all GeoTIFFs to tiles
        if: steps.check_current.outputs.current != 'true'
        run: python scripts/convert_faa_charts.py --chart-type ${{ matrix.chart_type }}

      - name: Delete old tiles from S3
        if: steps.check_current.outputs.current != 'true'
        run: |
          chart_type=${{ matrix.chart_type }}
          if [ -d "downloads/$chart_type" ]; then
            echo "Deleting old tiles for $chart_type from S3"
            aws s3 rm s3://$S3_BUCKET/$chart_type --recursive --only-show-errors
          else
            echo "No local directory for $chart_type, skipping S3 delete."
          fi

      - name: Upload tiles to S3
        if: steps.check_current.outputs.current != 'true'
        run: |
          set -euo pipefail
          echo "" > summary.txt
          chart_type=${{ matrix.chart_type }}
          if [ -d "downloads/$chart_type" ]; then
            echo "Uploading $chart_type to S3"
            if aws s3 sync \
              downloads/$chart_type \
              s3://$S3_BUCKET/$chart_type \
              --only-show-errors \
              --exclude "*" \
              --include "*.png" \
              --cache-control "public, max-age=31536000, immutable" \
            || {
              echo "Retrying upload...";
              sleep 10;
              aws s3 sync \
                downloads/$chart_type \
                s3://$S3_BUCKET/$chart_type \
                --only-show-errors \
                --exclude "*" \
                --include "*.png" \
                --cache-control "public, max-age=31536000, immutable";
            }; then
              echo "Successfully uploaded $chart_type to S3"
              echo "$chart_type uploaded" >> summary.txt
            else
              echo "Failed to upload $chart_type to S3" >&2
              echo "$chart_type FAILED" >> summary.txt
            fi
            echo ""
            echo ""
          else
            echo "No directory for $chart_type, skipping"
            echo "$chart_type missing" >> summary.txt
            echo ""
            echo ""
          fi
      - name: Check S3 Cache-Control header
        if: steps.check_current.outputs.current != 'true'
        run: |
          chart_type=${{ matrix.chart_type }}
          TILE_DIR=downloads/$chart_type
          if [ -d "$TILE_DIR" ]; then
            pip install boto3 botocore
            python scripts/test_cache_control.py "$S3_BUCKET" "$chart_type" "$TILE_DIR"
          else
            echo "No tile directory found for cache-control check."
          fi
      - name: Upload logs if failure
        if: failure()
        continue-on-error: true
        uses: actions/upload-artifact@v4
        with:
          name: conversion-logs-${{ matrix.chart_type }}
          path: logs/
      - name: Upload summary artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: summary-${{ matrix.chart_type }}
          path: summary.txt
          retention-days: 14
  notify_by_email:
    needs: download_convert_upload
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Download summary artifacts
        uses: actions/download-artifact@v4
        with:
          name: summary-sectional
      - name: Download summary artifacts
        uses: actions/download-artifact@v4
        with:
          name: summary-ifr_low
      - name: Download summary artifacts
        uses: actions/download-artifact@v4
        with:
          name: summary-ifr_high
      - name: Read and combine summaries
        id: read_summary
        run: |
          cat summary.txt summary-sectional/summary.txt summary-ifr_low/summary.txt summary-ifr_high/summary.txt > all_summaries.txt
          echo "summary<<EOF" >> $GITHUB_OUTPUT
          cat all_summaries.txt >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
      - name: Send email with job status
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 465
          secure: true
          username: ${{ secrets.EMAIL_USER }}
          password: ${{ secrets.EMAIL_PASSWORD }}
          subject: FAA Charts Job - ${{ needs.download_convert_upload.result }}
          to: lightoreflight@gmail.com
          from: GitHub Actions <lightoreflight@gmail.com>
          body: |
            FAA Charts workflow run completed with status: ${{ needs.download_convert_upload.result }}

            Repository: ${{ github.repository }}
            Workflow: ${{ github.workflow }}
            Run URL: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}

            Chart upload summary:
            ${{ steps.read_summary.outputs.summary }}
          attachments: all_summaries.txt
